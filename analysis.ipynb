{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Sep  8 12:31:52 2020\n",
        "\n",
        "@author: admin\n",
        "\"\"\"\n",
        "#%%\n",
        "'''import necessary packages. explain category encoder\n",
        "'''\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import category_encoders as ce\n",
        "\n",
        "\n",
        "dataset = results_df\n",
        "\n",
        "#%% \n",
        "'''data cleaning\n",
        "'''\n",
        "test = dataset.sample(n=1000)\n",
        "\n",
        "\n",
        "check = dataset['response duration'].isnull()\n",
        "print(check.value_counts())\n",
        "\n",
        "check = dataset['travel time'].isnull()\n",
        "temp = dataset['travel time'].value_counts()\n",
        "print(check.value_counts())\n",
        "\n",
        "temp = dataset['call_Type'].value_counts()\n",
        "\n",
        "goodMean = dataset['response duration'].mean(skipna = True)\n",
        "dataset['response duration'] = dataset['response duration'].fillna(goodMean)\n",
        "\n",
        "goodMean = dataset['travel time'].mean(skipna = True)\n",
        "dataset['travel time'] = dataset['travel time'].fillna(goodMean)\n",
        "\n",
        "dataset_clean = dataset[dataset['response duration']<15]\n",
        "\n",
        "dataset.columns\n",
        " \n",
        "#%% \n",
        "'''visualizations\n",
        "'''\n",
        "\n",
        "temp = dataset[dataset['response duration'].between(0,15)]\n",
        "plt.hist(temp['response duration'],bins = 30)\n",
        "\n",
        "temp = dataset[dataset['travel time'].between(0,15)]\n",
        "plt.hist(temp['travel time'],bins = 30)\n",
        "\n",
        "\n",
        "#%% \n",
        "'''encoding\n",
        "one-hot encode entire datasets BEFORE train/test split so we don't end up with train/test sets with different numbe of columns\n",
        "'''\n",
        "\n",
        " \n",
        "X = dataset.drop(['travel time','response duration','dispatch_dttm','response_dttm'], axis=1)\n",
        " \n",
        "encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
        "X_enc = encoder.fit_transform(X)\n",
        "#Xopt_enc = encoder.fit_transform(X_opt)\n",
        " \n",
        "encoder.categories_\n",
        " \n",
        "y = dataset[\"response duration\"].values\n",
        "df_map = pd.DataFrame({'original column':X.columns,\n",
        "                       'categories':encoder.categories_})\n",
        "\n",
        "#%% \n",
        "'''train/test split\n",
        "'''\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_enc, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(Xopt_enc, y, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_inv = -1*y_train\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "#%%\n",
        "'''obtain baseline predictive model\n",
        "'''\n",
        "\n",
        "avgDelay = np.full(y_test.shape, np.mean(y_train), dtype=float)\n",
        "\n",
        "#print(\"RMSE is {0}\".format(np.sqrt(mean_squared_error(y_test, avgDelay))))\n",
        "\n",
        "avgDelay\n",
        "\n",
        "mean_squared_error(y_test, avgDelay)\n",
        "\n",
        "#%% \n",
        "'''create models and queue\n",
        "'''\n",
        "\n",
        "if 'scores' not in locals():\n",
        "    scores = pd.DataFrame({'model':[],\n",
        "              'score':[]})\n",
        "\n",
        "verbosity = 3\n",
        "\n",
        "lr = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
        "sgdr = linear_model.SGDRegressor(max_iter=1000, tol =1e-3, verbose = 3)\n",
        "ridge = linear_model.Ridge(alpha = 0.01)\n",
        "ridge = linear_model.Ridge(alpha = 1)\n",
        "ridge_cv = linear_model.RidgeCV(alphas = [1e-1,1e0,1e1])\n",
        "lasso = linear_model.Lasso()\n",
        "lasso_cv = linear_model.LassoCV(alphas = [1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3], verbose = 3)\n",
        "linSVR1 = LinearSVR(C=0.1, verbose = 3)\n",
        "linSVR2 = LinearSVR(C=1, verbose = 3)\n",
        "linSVR3 = LinearSVR(C=10, verbose = 3)\n",
        "\n",
        "\n",
        "models = [lr,  sgdr,ridge,ridge_cv,lasso, lasso_cv]\n",
        "models = [lr,  sgdr,ridge, lasso, linSVR1]\n",
        "models = [ridge]\n",
        "\n",
        "#models = [lr, sgdr,ridge,lasso]\n",
        "#models = [linSVR1, linSVR2, linSVR3]\n",
        "#models = [lr]\n",
        "\n",
        "\t\t\t\t\t   \n",
        "importances = pd.DataFrame({'feature':encoder.get_feature_names()})\n",
        "importances['feature category'] = importances['feature'].str[1]\n",
        "\n",
        "\n",
        "\n",
        "#%% \n",
        "'''fit models to training set\n",
        "'''\n",
        "\n",
        "for i in range(len(models)):\n",
        "    print('fitting ',models[i])\n",
        "    \n",
        "    models[i].fit(X_train,y_train)\n",
        "    #models[i].fit(X_train,y_train_inv)\n",
        "    \n",
        "    models[i].predict(X_test)\n",
        "    modelScore = models[i].score(X_test, y_test)\n",
        "\n",
        "    scores = scores.append({'model':str(models[i].__class__.__name__),\n",
        "                              'score':modelScore},\n",
        "                              ignore_index = True)\n",
        "#%% tune hyperparameters of linear SVR\n",
        "\n",
        "turnon = False\n",
        "if turnon == True:\n",
        "    linSVRpreop = LinearSVR(verbose = 3, max_iter = 2000)\n",
        "    parameters = {'epsilon':[0.1, 1, 10], 'C':[0.1, 1, 10]}\n",
        "    svrOpt = GridSearchCV(linSVRpreop,parameters)\n",
        "    \n",
        "    svrOpt.fit(X_train,y_train)\n",
        "\n",
        "                      \n",
        "#%% \n",
        "'''compile feature importances\n",
        "'''\n",
        "\n",
        "for i in range(len(models)):\n",
        "    print('calculating feature importances for: ', models[i])\n",
        "    feIm = permutation_importance(models[i],X_train.toarray(), y_train, n_repeats = 5)\n",
        "    importances[str(models[i])] = feIm.importances_mean\n",
        "\n",
        "importances_pivot = pd.pivot_table(importances, index = 'feature category',aggfunc = 'mean')\n",
        "\n",
        "\n",
        "#%% \n",
        "''' some more visualizations\n",
        "'''\n",
        "\n",
        "def plotAgainst(dataset,column, y_axis):\n",
        "    dataset_piv = pd.pivot_table(dataset, index = column)\n",
        "    dataset_piv = dataset_piv.reset_index()\n",
        "    dataset_piv = dataset_piv.sort_values(by = y_axis)\n",
        "    plt.scatter(dataset_piv[column],dataset_piv[y_axis])\n",
        "    label = (y_axis, ' vs. ', column)\n",
        "    plt.title(label)\n",
        "\n",
        "for i in range(len(df_map)):\n",
        "    ds_fields = df_map['original column'].tolist()\n",
        "    plt.figure()\n",
        "    plotAgainst(dataset,ds_fields[i],'response duration') \n",
        "    plt.show()\n",
        "\n",
        "#%% \n",
        "'''try an ordinal encoder\n",
        "'''\n",
        "\n",
        "\n",
        "ordinalMapping = [{'col':'original_priority',\n",
        "                   'mapping':\n",
        "                            {'2':1,\n",
        "                            'B':2,\n",
        "                            'C':3,\n",
        "                            'A':4,\n",
        "                            'E':5,\n",
        "                            '3':6,\n",
        "                            'I':7}},\n",
        "                     {'col':'priority',\n",
        "                      'mapping':{\n",
        "                              '2':1,\n",
        "                              'E':2,\n",
        "                              '3':3}},\n",
        "                      {'col':'number_of_alarms',\n",
        "                       'mapping':\n",
        "                           {'1':1,\n",
        "                            '2':2}\n",
        "                              }]\n",
        "                    \n",
        "                                  \n",
        "\n",
        "ordEnc = ce.OrdinalEncoder(mapping = ordinalMapping)\n",
        "X_opt = ordEnc.fit_transform(X)\n",
        "X_opt = X_opt.astype({'original_priority':'int64','priority':'int64', 'number_of_alarms':'int64'})\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}